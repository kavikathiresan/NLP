{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "ZZm4NlksvxYE"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8K5vJw6u0yMe",
        "outputId": "b67ead6e-8eb2-426f-fab0-1d5d96ac5139"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Import the package and load the **text** **bold text**"
      ],
      "metadata": {
        "id": "y-vWcSffx2XS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"\"\"Manually analyzing hundreds of unstructured text-based data sources is tedious and time-consuming. What's worse is that since it's in text format, you know this process can be made easier, but you're unsure how to do it.\n",
        "If you’re in a data-driven company that relies on such data sources to make critical decisions to optimize and improve your customer experience processes, keep reading And he's right. Too often, we get stuck in the DRIP syndrome where we're happily generating data—but can't generate meaningful insights from them. Also, when you consider that 80% to 90% of data is unstructured, there’s so much potential waiting to be unlocked.\n",
        "In this article, we’ll discuss the concept of textual data and how you can use it to extract valuable insights for your customer support operations.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "grLVh28YxOHe"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "text-Collected data"
      ],
      "metadata": {
        "id": "BjUDcP4u0Yzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHnwCZTLxivc",
        "outputId": "0b300f54-3052-4160-fc92-0b1b51861c52"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manually analyzing hundreds of unstructured text-based data sources is tedious and time-consuming. What's worse is that since it's in text format, you know this process can be made easier, but you're unsure how to do it.\n",
            "If you’re in a data-driven company that relies on such data sources to make critical decisions to optimize and improve your customer experience processes, keep reading And he's right. Too often, we get stuck in the DRIP syndrome where we're happily generating data—but can't generate meaningful insights from them. Also, when you consider that 80% to 90% of data is unstructured, there’s so much potential waiting to be unlocked.\n",
            "In this article, we’ll discuss the concept of textual data and how you can use it to extract valuable insights for your customer support operations.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2.**Tokenization** -Sentence and Word\n",
        "\n",
        "\n",
        "1.  SENTENCE-gives total no of sentences in text data\n",
        "2.  Word- gives the total no word in text data\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "slgy7Tyfx_FT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "total_sentences = sent_tokenize(text)\n",
        "print(total_sentences)\n",
        "print()\n",
        "print(f'total sentence in data:{len(total_sentences)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R68biT4myH-7",
        "outputId": "c920394f-d553-4dca-a176-c36604c717e3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Manually analyzing hundreds of unstructured text-based data sources is tedious and time-consuming.', \"What's worse is that since it's in text format, you know this process can be made easier, but you're unsure how to do it.\", \"If you’re in a data-driven company that relies on such data sources to make critical decisions to optimize and improve your customer experience processes, keep reading And he's right.\", \"Too often, we get stuck in the DRIP syndrome where we're happily generating data—but can't generate meaningful insights from them.\", 'Also, when you consider that 80% to 90% of data is unstructured, there’s so much potential waiting to be unlocked.', 'In this article, we’ll discuss the concept of textual data and how you can use it to extract valuable insights for your customer support operations.']\n",
            "\n",
            "total sentence in data:6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "total_words = word_tokenize(text)\n",
        "print(total_words)\n",
        "print()\n",
        "print(f'total word in data:{len(total_words)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DH1ZeBIE03NN",
        "outputId": "7511d521-b5ca-45d4-a9e1-28a556fe9475"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Manually', 'analyzing', 'hundreds', 'of', 'unstructured', 'text-based', 'data', 'sources', 'is', 'tedious', 'and', 'time-consuming', '.', 'What', \"'s\", 'worse', 'is', 'that', 'since', 'it', \"'s\", 'in', 'text', 'format', ',', 'you', 'know', 'this', 'process', 'can', 'be', 'made', 'easier', ',', 'but', 'you', \"'re\", 'unsure', 'how', 'to', 'do', 'it', '.', 'If', 'you', '’', 're', 'in', 'a', 'data-driven', 'company', 'that', 'relies', 'on', 'such', 'data', 'sources', 'to', 'make', 'critical', 'decisions', 'to', 'optimize', 'and', 'improve', 'your', 'customer', 'experience', 'processes', ',', 'keep', 'reading', 'And', 'he', \"'s\", 'right', '.', 'Too', 'often', ',', 'we', 'get', 'stuck', 'in', 'the', 'DRIP', 'syndrome', 'where', 'we', \"'re\", 'happily', 'generating', 'data—but', 'ca', \"n't\", 'generate', 'meaningful', 'insights', 'from', 'them', '.', 'Also', ',', 'when', 'you', 'consider', 'that', '80', '%', 'to', '90', '%', 'of', 'data', 'is', 'unstructured', ',', 'there', '’', 's', 'so', 'much', 'potential', 'waiting', 'to', 'be', 'unlocked', '.', 'In', 'this', 'article', ',', 'we', '’', 'll', 'discuss', 'the', 'concept', 'of', 'textual', 'data', 'and', 'how', 'you', 'can', 'use', 'it', 'to', 'extract', 'valuable', 'insights', 'for', 'your', 'customer', 'support', 'operations', '.']\n",
            "\n",
            "total word in data:157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Remove the **Punctuations**"
      ],
      "metadata": {
        "id": "HxA8Xg683muh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n"
      ],
      "metadata": {
        "id": "6euW7fzG3f_8"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string.punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "iNJATwMPNT18",
        "outputId": "1c49d6a4-6721-4306-dbc5-93e54967df1c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text=[]\n",
        "for i in text:\n",
        "  if i not in string.punctuation:\n",
        "    clean_text.append(i)\n",
        "proper_text= ''.join(clean_text)\n",
        "print(proper_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgkNUmnH39JL",
        "outputId": "8bd14820-3936-43aa-a1d1-84b07bd6656d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manually analyzing hundreds of unstructured textbased data sources is tedious and timeconsuming Whats worse is that since its in text format you know this process can be made easier but youre unsure how to do it\n",
            "If you’re in a datadriven company that relies on such data sources to make critical decisions to optimize and improve your customer experience processes keep reading And hes right Too often we get stuck in the DRIP syndrome where were happily generating data—but cant generate meaningful insights from them Also when you consider that 80 to 90 of data is unstructured there’s so much potential waiting to be unlocked\n",
            "In this article we’ll discuss the concept of textual data and how you can use it to extract valuable insights for your customer support operations\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lower the text so developing the application will be easy to be trained"
      ],
      "metadata": {
        "id": "8_qORYIlRzMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "proper_text=proper_text.lower()"
      ],
      "metadata": {
        "id": "3Z9rJ_iASANy"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proper_text"
      ],
      "metadata": {
        "id": "BNtqYP9F5Nnk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "9c8360d5-c5d2-4d6f-b1da-50c2ce5fe7a0"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'manually analyzing hundreds of unstructured textbased data sources is tedious and timeconsuming whats worse is that since its in text format you know this process can be made easier but youre unsure how to do it\\nif you’re in a datadriven company that relies on such data sources to make critical decisions to optimize and improve your customer experience processes keep reading and hes right too often we get stuck in the drip syndrome where were happily generating data—but cant generate meaningful insights from them also when you consider that 80 to 90 of data is unstructured there’s so much potential waiting to be unlocked\\nin this article we’ll discuss the concept of textual data and how you can use it to extract valuable insights for your customer support operations\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.Stopwords**- there are few words wch doesn't carry information"
      ],
      "metadata": {
        "id": "5GEh1Z_3S6KE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aix1nBzGVPbZ",
        "outputId": "9a8542c5-949c-4cbc-9b1e-438f0f9c0002"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "PeuyHw4gS4AZ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text=[]\n",
        "for i in proper_text.split():\n",
        "  if i not in stopwords.words('english'):\n",
        "    cleaned_text.append(i)\n",
        "final_data=' '.join(cleaned_text)\n",
        "print(final_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLQuHsN5TsMq",
        "outputId": "adab27ba-17c3-4c19-c662-524d0d6274c6"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "manually analyzing hundreds unstructured textbased data sources tedious timeconsuming whats worse since text format know process made easier youre unsure you’re datadriven company relies data sources make critical decisions optimize improve customer experience processes keep reading hes right often get stuck drip syndrome happily generating data—but cant generate meaningful insights also consider 80 90 data unstructured there’s much potential waiting unlocked article we’ll discuss concept textual data use extract valuable insights customer support operations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.Stemming and Lemmatization**\n",
        "\n",
        "\n",
        "1.   Stemming-it does'nt work so well because it didn't understand the past,past,future word and take only common words\n",
        "2.    Lemmatization-it work so well because it  understand the past,past,future words\n",
        "\n"
      ],
      "metadata": {
        "id": "tOqxQSAxWfOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWhGHEAzWWkY",
        "outputId": "5b0089b5-b55d-40e1-e4ca-d1da7a458170"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "yTDrYnCvaZIf"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stemming on my data\n",
        "stemming=PorterStemmer()\n",
        "for i in final_data.split():\n",
        "  print(\"before stemming:\",i,\"after stemming word is:\",stemming.stem(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99oWzS1-akO2",
        "outputId": "73fd805d-a1ae-48fd-f6a6-2cba749c0fcd"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before stemming: manually after stemming word is: manual\n",
            "before stemming: analyzing after stemming word is: analyz\n",
            "before stemming: hundreds after stemming word is: hundr\n",
            "before stemming: unstructured after stemming word is: unstructur\n",
            "before stemming: textbased after stemming word is: textbas\n",
            "before stemming: data after stemming word is: data\n",
            "before stemming: sources after stemming word is: sourc\n",
            "before stemming: tedious after stemming word is: tediou\n",
            "before stemming: timeconsuming after stemming word is: timeconsum\n",
            "before stemming: whats after stemming word is: what\n",
            "before stemming: worse after stemming word is: wors\n",
            "before stemming: since after stemming word is: sinc\n",
            "before stemming: text after stemming word is: text\n",
            "before stemming: format after stemming word is: format\n",
            "before stemming: know after stemming word is: know\n",
            "before stemming: process after stemming word is: process\n",
            "before stemming: made after stemming word is: made\n",
            "before stemming: easier after stemming word is: easier\n",
            "before stemming: youre after stemming word is: your\n",
            "before stemming: unsure after stemming word is: unsur\n",
            "before stemming: you’re after stemming word is: you’r\n",
            "before stemming: datadriven after stemming word is: datadriven\n",
            "before stemming: company after stemming word is: compani\n",
            "before stemming: relies after stemming word is: reli\n",
            "before stemming: data after stemming word is: data\n",
            "before stemming: sources after stemming word is: sourc\n",
            "before stemming: make after stemming word is: make\n",
            "before stemming: critical after stemming word is: critic\n",
            "before stemming: decisions after stemming word is: decis\n",
            "before stemming: optimize after stemming word is: optim\n",
            "before stemming: improve after stemming word is: improv\n",
            "before stemming: customer after stemming word is: custom\n",
            "before stemming: experience after stemming word is: experi\n",
            "before stemming: processes after stemming word is: process\n",
            "before stemming: keep after stemming word is: keep\n",
            "before stemming: reading after stemming word is: read\n",
            "before stemming: hes after stemming word is: he\n",
            "before stemming: right after stemming word is: right\n",
            "before stemming: often after stemming word is: often\n",
            "before stemming: get after stemming word is: get\n",
            "before stemming: stuck after stemming word is: stuck\n",
            "before stemming: drip after stemming word is: drip\n",
            "before stemming: syndrome after stemming word is: syndrom\n",
            "before stemming: happily after stemming word is: happili\n",
            "before stemming: generating after stemming word is: gener\n",
            "before stemming: data—but after stemming word is: data—but\n",
            "before stemming: cant after stemming word is: cant\n",
            "before stemming: generate after stemming word is: gener\n",
            "before stemming: meaningful after stemming word is: meaning\n",
            "before stemming: insights after stemming word is: insight\n",
            "before stemming: also after stemming word is: also\n",
            "before stemming: consider after stemming word is: consid\n",
            "before stemming: 80 after stemming word is: 80\n",
            "before stemming: 90 after stemming word is: 90\n",
            "before stemming: data after stemming word is: data\n",
            "before stemming: unstructured after stemming word is: unstructur\n",
            "before stemming: there’s after stemming word is: there’\n",
            "before stemming: much after stemming word is: much\n",
            "before stemming: potential after stemming word is: potenti\n",
            "before stemming: waiting after stemming word is: wait\n",
            "before stemming: unlocked after stemming word is: unlock\n",
            "before stemming: article after stemming word is: articl\n",
            "before stemming: we’ll after stemming word is: we’ll\n",
            "before stemming: discuss after stemming word is: discuss\n",
            "before stemming: concept after stemming word is: concept\n",
            "before stemming: textual after stemming word is: textual\n",
            "before stemming: data after stemming word is: data\n",
            "before stemming: use after stemming word is: use\n",
            "before stemming: extract after stemming word is: extract\n",
            "before stemming: valuable after stemming word is: valuabl\n",
            "before stemming: insights after stemming word is: insight\n",
            "before stemming: customer after stemming word is: custom\n",
            "before stemming: support after stemming word is: support\n",
            "before stemming: operations after stemming word is: oper\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "rvguUsPHafZf"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatization=WordNetLemmatizer()\n",
        "for i in final_data.split():\n",
        "  print('before lemmatization',i,'after lemmatization:',lemmatization.lemmatize(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HCYn5sLcDXu",
        "outputId": "c4bfccc4-6c01-4091-ceb3-0ef3b03d3427"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before lemmatization manually after lemmatization: manually\n",
            "before lemmatization analyzing after lemmatization: analyzing\n",
            "before lemmatization hundreds after lemmatization: hundred\n",
            "before lemmatization unstructured after lemmatization: unstructured\n",
            "before lemmatization textbased after lemmatization: textbased\n",
            "before lemmatization data after lemmatization: data\n",
            "before lemmatization sources after lemmatization: source\n",
            "before lemmatization tedious after lemmatization: tedious\n",
            "before lemmatization timeconsuming after lemmatization: timeconsuming\n",
            "before lemmatization whats after lemmatization: whats\n",
            "before lemmatization worse after lemmatization: worse\n",
            "before lemmatization since after lemmatization: since\n",
            "before lemmatization text after lemmatization: text\n",
            "before lemmatization format after lemmatization: format\n",
            "before lemmatization know after lemmatization: know\n",
            "before lemmatization process after lemmatization: process\n",
            "before lemmatization made after lemmatization: made\n",
            "before lemmatization easier after lemmatization: easier\n",
            "before lemmatization youre after lemmatization: youre\n",
            "before lemmatization unsure after lemmatization: unsure\n",
            "before lemmatization you’re after lemmatization: you’re\n",
            "before lemmatization datadriven after lemmatization: datadriven\n",
            "before lemmatization company after lemmatization: company\n",
            "before lemmatization relies after lemmatization: relies\n",
            "before lemmatization data after lemmatization: data\n",
            "before lemmatization sources after lemmatization: source\n",
            "before lemmatization make after lemmatization: make\n",
            "before lemmatization critical after lemmatization: critical\n",
            "before lemmatization decisions after lemmatization: decision\n",
            "before lemmatization optimize after lemmatization: optimize\n",
            "before lemmatization improve after lemmatization: improve\n",
            "before lemmatization customer after lemmatization: customer\n",
            "before lemmatization experience after lemmatization: experience\n",
            "before lemmatization processes after lemmatization: process\n",
            "before lemmatization keep after lemmatization: keep\n",
            "before lemmatization reading after lemmatization: reading\n",
            "before lemmatization hes after lemmatization: he\n",
            "before lemmatization right after lemmatization: right\n",
            "before lemmatization often after lemmatization: often\n",
            "before lemmatization get after lemmatization: get\n",
            "before lemmatization stuck after lemmatization: stuck\n",
            "before lemmatization drip after lemmatization: drip\n",
            "before lemmatization syndrome after lemmatization: syndrome\n",
            "before lemmatization happily after lemmatization: happily\n",
            "before lemmatization generating after lemmatization: generating\n",
            "before lemmatization data—but after lemmatization: data—but\n",
            "before lemmatization cant after lemmatization: cant\n",
            "before lemmatization generate after lemmatization: generate\n",
            "before lemmatization meaningful after lemmatization: meaningful\n",
            "before lemmatization insights after lemmatization: insight\n",
            "before lemmatization also after lemmatization: also\n",
            "before lemmatization consider after lemmatization: consider\n",
            "before lemmatization 80 after lemmatization: 80\n",
            "before lemmatization 90 after lemmatization: 90\n",
            "before lemmatization data after lemmatization: data\n",
            "before lemmatization unstructured after lemmatization: unstructured\n",
            "before lemmatization there’s after lemmatization: there’s\n",
            "before lemmatization much after lemmatization: much\n",
            "before lemmatization potential after lemmatization: potential\n",
            "before lemmatization waiting after lemmatization: waiting\n",
            "before lemmatization unlocked after lemmatization: unlocked\n",
            "before lemmatization article after lemmatization: article\n",
            "before lemmatization we’ll after lemmatization: we’ll\n",
            "before lemmatization discuss after lemmatization: discus\n",
            "before lemmatization concept after lemmatization: concept\n",
            "before lemmatization textual after lemmatization: textual\n",
            "before lemmatization data after lemmatization: data\n",
            "before lemmatization use after lemmatization: use\n",
            "before lemmatization extract after lemmatization: extract\n",
            "before lemmatization valuable after lemmatization: valuable\n",
            "before lemmatization insights after lemmatization: insight\n",
            "before lemmatization customer after lemmatization: customer\n",
            "before lemmatization support after lemmatization: support\n",
            "before lemmatization operations after lemmatization: operation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking only on application -Lemmatize"
      ],
      "metadata": {
        "id": "0DMgX0qqd10_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_data=[]\n",
        "lemmatization=WordNetLemmatizer()\n",
        "for i in final_data.split():\n",
        "  lemmatized_data.append(lemmatization.lemmatize(i))\n",
        "lemmatized_datas=' '.join(lemmatized_data)\n",
        "print(lemmatized_datas)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGL4ieMGd8M6",
        "outputId": "1dd1b1fd-537a-4153-a427-33947385bfc0"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "manually analyzing hundred unstructured textbased data source tedious timeconsuming whats worse since text format know process made easier youre unsure you’re datadriven company relies data source make critical decision optimize improve customer experience process keep reading he right often get stuck drip syndrome happily generating data—but cant generate meaningful insight also consider 80 90 data unstructured there’s much potential waiting unlocked article we’ll discus concept textual data use extract valuable insight customer support operation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.\n",
        "\n",
        "1.   Bag words - Based on words having same priority how the neural networks will learn the\n",
        "\n",
        "2.   Term Frequency and Inverse Document Frequency - to make some differences we use TF-IDF\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3zm_JGXvlqVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sklearn"
      ],
      "metadata": {
        "id": "POJyJ_ASYFid"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "res=CountVectorizer()\n",
        "text_bag= res.fit_transform([lemmatized_datas])\n",
        "\n",
        "print(text_bag.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45JQucoUljiA",
        "outputId": "62835d9a-90d9-49ea-9f16-7754c09566de"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 1 1 1 1 1 1 1 1 2 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1\n",
            "  1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "afan_xAGqXf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "r=TfidfVectorizer()\n",
        "text_Tfid= r.fit_transform([lemmatized_datas])\n",
        "\n",
        "print(text_Tfid.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGVrppUWi7rc",
        "outputId": "ac49a494-45ac-4d71-bde8-1fe150137474"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.09667365 0.09667365 0.09667365 0.09667365 0.09667365 0.09667365\n",
            "  0.09667365 0.09667365 0.09667365 0.09667365 0.09667365 0.1933473\n",
            "  0.48336824 0.09667365 0.09667365 0.09667365 0.09667365 0.09667365\n",
            "  0.09667365 0.09667365 0.09667365 0.09667365 0.09667365 0.09667365\n",
            "  0.09667365 0.09667365 0.09667365 0.09667365 0.1933473  0.09667365\n",
            "  0.09667365 0.09667365 0.09667365 0.09667365 0.09667365 0.09667365\n",
            "  0.09667365 0.09667365 0.09667365 0.09667365 0.09667365 0.1933473\n",
            "  0.09667365 0.09667365 0.09667365 0.09667365 0.09667365 0.1933473\n",
            "  0.09667365 0.09667365 0.09667365 0.09667365 0.09667365 0.09667365\n",
            "  0.09667365 0.09667365 0.09667365 0.09667365 0.1933473  0.09667365\n",
            "  0.09667365 0.09667365 0.09667365 0.09667365 0.09667365 0.09667365\n",
            "  0.09667365 0.09667365]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "76d7Hb3WqHjR"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs=['manually analyzing hundred unstructured textbased data source tedious timeconsuming whats worse since text format know process made easier youre unsure you’re datadriven company relies data source make critical decision optimize improve customer experience process keep reading he right often get stuck drip syndrome happily generating data—but cant generate meaningful insight also consider 80 90 data unstructured there’s much potential waiting unlocked article we’ll discus concept textual data use extract valuable insight customer support operation']\n"
      ],
      "metadata": {
        "id": "R6vDp9l2uyq2"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=100\n",
        "encoded_docs=[one_hot(d,vocab_size) for d in docs]\n",
        "print(encoded_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ugl4JfetuS76",
        "outputId": "a3a4804c-eee9-4ffe-833d-0b1d2e887934"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[91, 47, 89, 42, 48, 26, 36, 26, 36, 77, 23, 73, 18, 11, 3, 44, 53, 26, 25, 46, 5, 93, 99, 26, 26, 36, 19, 90, 88, 39, 10, 92, 22, 44, 8, 15, 39, 85, 36, 15, 32, 57, 49, 68, 66, 88, 9, 80, 14, 74, 84, 62, 71, 47, 26, 42, 98, 55, 88, 65, 23, 91, 76, 90, 9, 48, 26, 6, 17, 7, 74, 92, 83, 99]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length=4\n",
        "pad_sequences=pad_sequences(encoded_docs,maxlen=max_length,padding='post')\n",
        "print(pad_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v__38rRfxpXD",
        "outputId": "6bc4c872-a191-4b1c-8881-a8dcca598a8f"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[74 92 83 99]]\n"
          ]
        }
      ]
    }
  ]
}